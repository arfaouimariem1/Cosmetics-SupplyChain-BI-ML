{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30dfda4c",
   "metadata": {},
   "source": [
    "# Deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6337e079",
   "metadata": {},
   "source": [
    "# classer si les les cartons sont damaged ou non ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddb18b06",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyodbc'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyodbc\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mio\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pyodbc'"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import numpy as np\n",
    "import io\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Connexion SQL Server\n",
    "conn = pyodbc.connect(\n",
    "    'DRIVER={SQL Server};'\n",
    "    'SERVER=DESKTOP-8C3VSOH;'\n",
    "    'DATABASE=SuplyChain_DataWarehouse;'\n",
    "    'Trusted_Connection=yes;'\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Chargement des images depuis SQL\n",
    "def load_images(dataset_type):\n",
    "    cursor.execute(f\"SELECT image, label FROM Images WHERE dataset_type = ?\", dataset_type)\n",
    "    rows = cursor.fetchall() #    Stocke tous les résultats (chaque ligne = une image + un label) dans la variable rows.\n",
    "    X, y = [], [] #X stockera les images (sous forme de tableaux numpy) // #y stockera les étiquettes (0 ou 1).\n",
    "\n",
    "    for row in rows:\n",
    "        try:\n",
    "            img = Image.open(io.BytesIO(row[0])).convert(\"RGB\").resize((64, 64)) #io.BytesIO(row[0]) : convertit le binaire en un flux lisible.\n",
    "            X.append(np.array(img))  # Ajout de l’image au dataset\n",
    "            y.append(0 if row[1] == \"undamagedpackages\" else 1)  # Conversion du label en chiffre\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur image : {e}\")\n",
    "    return np.array(X) / 255.0, np.array(y)\n",
    "#np.array(X) : convertit la liste des images en tableau numpy.\n",
    "#/ 255.0 : normalise les valeurs des pixels entre 0 et 1 (car ils vont de 0 à 255).\n",
    "#np.array(y) : convertit la liste des étiquettes en tableau numpy.\n",
    "\n",
    "# Chargement des données\n",
    "X_train, y_train = load_images(\"train\")\n",
    "X_valid, y_valid = load_images(\"valid\")\n",
    "X_test, y_test   = load_images(\"test\")\n",
    "\n",
    "# Data Augmentation Quand on n’a pas beaucoup d’images dans l’ensemble d'entraînement, le modèle risque de sur-apprendre (overfitting).\n",
    "# La data augmentation simule de nouvelles images à partir de celles qu’on a déjà, en appliquant des transformations aléatoires réalistes.\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Architecture du modèle\n",
    "model = Sequential([ #chaque couche est ajoutée l’une après l’autre (modèle linéaire)\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3), kernel_regularizer=l2(0.001)), # 1re couche convolutionnelle \n",
    "    #Conv2D(32, (3,3)) : crée 32 filtres (ou kernels) de taille 3x3.activation='relu' : applique la fonction ReLU (Rectified Linear Unit) pour introduire de la non-linéarité.\n",
    "    MaxPooling2D(2, 2), #Applique une réduction de dimension \n",
    "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(), #Transforme les données 2D en 1D (vecteur) pour pouvoir les passer à des couches entièrement connectées (Dense).\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    Dropout(0.5), #Désactive aléatoirement 50% des neurones pendant l’entraînement. #Sert à éviter que le réseau devienne dépendant de certains neurones (encore contre l’overfitting).\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compilation\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "#  Calcul des poids des classes Équilibrage des classes\n",
    "#Par exemple, si tu as beaucoup de undamaged et peu de damaged, cette méthode donne plus d’importance aux damaged\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(\"Class Weights:\", class_weights)\n",
    "\n",
    "# Entraînement\n",
    "history = model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=32), # applique en temps réel les transformations (rotation, zoom…)\n",
    "    epochs=50, #nombre maximal d’itérations sur tout le dataset.\n",
    "    validation_data=(X_valid, y_valid), #utilisé pour surveiller val_loss pendant l’entraînement.\n",
    "    callbacks=[early_stop],\n",
    "    class_weight=class_weights\n",
    ")\n",
    "\n",
    "# === ÉVALUATION TEST ===\n",
    "y_pred_prob = model.predict(X_test).flatten()\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "print(\"=== Résultats TEST ===\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"undamaged\", \"damaged\"]))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[\"undamaged\", \"damaged\"],\n",
    "            yticklabels=[\"undamaged\", \"damaged\"])\n",
    "plt.xlabel(\"Prédiction\")\n",
    "plt.ylabel(\"Vraie classe\")\n",
    "plt.title(\"Matrice de confusion - TEST\")\n",
    "plt.show()\n",
    "\n",
    "# === ÉVALUATION VALIDATION ===\n",
    "y_val_pred_prob = model.predict(X_valid).flatten()\n",
    "y_val_pred = (y_val_pred_prob > 0.5).astype(int)\n",
    "\n",
    "print(\"=== Résultats VALIDATION ===\")\n",
    "print(classification_report(y_valid, y_val_pred, target_names=[\"undamaged\", \"damaged\"]))\n",
    "\n",
    "cm_val = confusion_matrix(y_valid, y_val_pred)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm_val, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=[\"undamaged\", \"damaged\"],\n",
    "            yticklabels=[\"undamaged\", \"damaged\"])\n",
    "plt.xlabel(\"Prédiction\")\n",
    "plt.ylabel(\"Vraie classe\")\n",
    "plt.title(\"Matrice de confusion - VALIDATION\")\n",
    "plt.show()\n",
    "\n",
    "# === COURBES D'APPRENTISSAGE ===\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Valid Acc')\n",
    "plt.title('Courbe de précision')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Valid Loss')\n",
    "plt.title('Courbe de perte')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66477897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"cnn_damage_detector.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd68b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1 : Vrai = damaged | Prédit = undamaged\n",
      "Image 2 : Vrai = damaged | Prédit = damaged\n",
      "Image 3 : Vrai = damaged | Prédit = damaged\n",
      "Image 4 : Vrai = damaged | Prédit = undamaged\n",
      "Image 5 : Vrai = damaged | Prédit = damaged\n",
      "Image 6 : Vrai = damaged | Prédit = damaged\n",
      "Image 7 : Vrai = damaged | Prédit = damaged\n",
      "Image 8 : Vrai = damaged | Prédit = damaged\n",
      "Image 9 : Vrai = damaged | Prédit = damaged\n",
      "Image 10 : Vrai = damaged | Prédit = damaged\n",
      "Image 11 : Vrai = damaged | Prédit = undamaged\n",
      "Image 12 : Vrai = damaged | Prédit = damaged\n",
      "Image 13 : Vrai = damaged | Prédit = damaged\n",
      "Image 14 : Vrai = damaged | Prédit = damaged\n",
      "Image 15 : Vrai = damaged | Prédit = damaged\n",
      "Image 16 : Vrai = damaged | Prédit = undamaged\n",
      "Image 17 : Vrai = damaged | Prédit = damaged\n",
      "Image 18 : Vrai = damaged | Prédit = undamaged\n",
      "Image 19 : Vrai = damaged | Prédit = damaged\n",
      "Image 20 : Vrai = damaged | Prédit = damaged\n",
      "Image 21 : Vrai = damaged | Prédit = damaged\n",
      "Image 22 : Vrai = damaged | Prédit = damaged\n",
      "Image 23 : Vrai = damaged | Prédit = damaged\n",
      "Image 24 : Vrai = damaged | Prédit = undamaged\n",
      "Image 25 : Vrai = damaged | Prédit = damaged\n",
      "Image 26 : Vrai = damaged | Prédit = undamaged\n",
      "Image 27 : Vrai = damaged | Prédit = damaged\n",
      "Image 28 : Vrai = damaged | Prédit = undamaged\n",
      "Image 29 : Vrai = damaged | Prédit = damaged\n",
      "Image 30 : Vrai = damaged | Prédit = damaged\n",
      "Image 31 : Vrai = damaged | Prédit = damaged\n",
      "Image 32 : Vrai = damaged | Prédit = damaged\n",
      "Image 33 : Vrai = damaged | Prédit = undamaged\n",
      "Image 34 : Vrai = damaged | Prédit = damaged\n",
      "Image 35 : Vrai = damaged | Prédit = damaged\n",
      "Image 36 : Vrai = damaged | Prédit = damaged\n",
      "Image 37 : Vrai = damaged | Prédit = undamaged\n",
      "Image 38 : Vrai = damaged | Prédit = damaged\n",
      "Image 39 : Vrai = damaged | Prédit = damaged\n",
      "Image 40 : Vrai = damaged | Prédit = damaged\n",
      "Image 41 : Vrai = damaged | Prédit = damaged\n",
      "Image 42 : Vrai = damaged | Prédit = undamaged\n",
      "Image 43 : Vrai = damaged | Prédit = damaged\n",
      "Image 44 : Vrai = damaged | Prédit = damaged\n",
      "Image 45 : Vrai = damaged | Prédit = damaged\n",
      "Image 46 : Vrai = damaged | Prédit = damaged\n",
      "Image 47 : Vrai = damaged | Prédit = damaged\n",
      "Image 48 : Vrai = damaged | Prédit = damaged\n",
      "Image 49 : Vrai = damaged | Prédit = damaged\n",
      "Image 50 : Vrai = damaged | Prédit = undamaged\n",
      "Image 51 : Vrai = damaged | Prédit = undamaged\n",
      "Image 52 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 53 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 54 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 55 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 56 : Vrai = undamaged | Prédit = damaged\n",
      "Image 57 : Vrai = undamaged | Prédit = damaged\n",
      "Image 58 : Vrai = undamaged | Prédit = damaged\n",
      "Image 59 : Vrai = undamaged | Prédit = damaged\n",
      "Image 60 : Vrai = undamaged | Prédit = damaged\n",
      "Image 61 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 62 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 63 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 64 : Vrai = undamaged | Prédit = damaged\n",
      "Image 65 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 66 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 67 : Vrai = undamaged | Prédit = damaged\n",
      "Image 68 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 69 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 70 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 71 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 72 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 73 : Vrai = undamaged | Prédit = damaged\n",
      "Image 74 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 75 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 76 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 77 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 78 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 79 : Vrai = undamaged | Prédit = damaged\n",
      "Image 80 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 81 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 82 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 83 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 84 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 85 : Vrai = undamaged | Prédit = damaged\n",
      "Image 86 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 87 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 88 : Vrai = undamaged | Prédit = damaged\n",
      "Image 89 : Vrai = undamaged | Prédit = damaged\n",
      "Image 90 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 91 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 92 : Vrai = undamaged | Prédit = damaged\n",
      "Image 93 : Vrai = undamaged | Prédit = damaged\n",
      "Image 94 : Vrai = undamaged | Prédit = damaged\n",
      "Image 95 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 96 : Vrai = undamaged | Prédit = damaged\n",
      "Image 97 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 98 : Vrai = undamaged | Prédit = damaged\n",
      "Image 99 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 100 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 101 : Vrai = undamaged | Prédit = undamaged\n",
      "Image 102 : Vrai = undamaged | Prédit = undamaged\n"
     ]
    }
   ],
   "source": [
    "# Afficher les résultats image par image\n",
    "for i in range(len(y_test)):\n",
    "    vrai = \"damaged\" if y_test[i] == 1 else \"undamaged\"\n",
    "    predit = \"damaged\" if y_pred[i] == 1 else \"undamaged\"\n",
    "    print(f\"Image {i+1} : Vrai = {vrai} | Prédit = {predit}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backend-flask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
